{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning\n\nLLM: \n- https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32\n\nSent-Transformer:\n- https://huggingface.co/blog/how-to-train-sentence-transformers\n- https://huggingface.co/datasets/snli\n","metadata":{}},{"cell_type":"markdown","source":"Installations","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!pip install openai transformers sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:01:05.378692Z","iopub.execute_input":"2023-09-27T09:01:05.379084Z","iopub.status.idle":"2023-09-27T09:01:25.317263Z","shell.execute_reply.started":"2023-09-27T09:01:05.379052Z","shell.execute_reply":"2023-09-27T09:01:25.315511Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import re\nimport sqlite3\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import spatial\n\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\nfrom sentence_transformers import SentenceTransformer\nimport openai","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:01:25.319563Z","iopub.execute_input":"2023-09-27T09:01:25.319921Z","iopub.status.idle":"2023-09-27T09:01:46.189168Z","shell.execute_reply.started":"2023-09-27T09:01:25.319889Z","shell.execute_reply":"2023-09-27T09:01:46.187983Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Using OpenAI","metadata":{}},{"cell_type":"code","source":"# If running on Kaggle, add your OpenAI API key to the secrets\nfrom kaggle_secrets import UserSecretsClient\nopenai.api_key = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")\n\n# # if running locally, use this instead\n# import os\n# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n# ChatGPT using openAI API\ndef openai_generate(prompt: str, llm_model: str = \"text-davinci-003\"):\n    res = openai.Completion.create(\n        model=llm_model,\n        prompt=prompt,\n        temperature=0,\n        max_tokens=1024,\n    )\n    \n    choice = res.choices[0]\n    if choice.finish_reason != \"stop\":\n        raise Exception(f\"finish reason: {choice.finish_reason}\")\n    return choice.text\n\n# Get the arguments from the prompt\n# e.g. Sum up all {statement}s and {fact}s -> [\"statement\", \"fact\"]\ndef get_keys(s: str): \n    res = re.findall(r\"\\{\\S+?\\}\", s)\n    res = [re.sub(r\"[\\{\\}]\", '', item) for item in res]\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:01:52.228434Z","iopub.execute_input":"2023-09-27T09:01:52.229245Z","iopub.status.idle":"2023-09-27T09:01:52.416735Z","shell.execute_reply.started":"2023-09-27T09:01:52.229204Z","shell.execute_reply":"2023-09-27T09:01:52.415393Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Named Entity Recognition (NER) using BERT Transformers","metadata":{}},{"cell_type":"code","source":"ner_options = dict(\n    tokenizer = \"dslim/bert-base-NER\",\n    model = \"dslim/bert-base-NER\",\n)\n\nner_tokenizer = AutoTokenizer.from_pretrained(ner_options[\"tokenizer\"])\nner_model = AutoModelForTokenClassification.from_pretrained(ner_options[\"model\"])\nner = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n\n# get important topics / tags of a sentence\ndef topics(sentence, ner = ner):\n    raw_entities = {}\n    for token in ner(sentence):\n        if '#' in token[\"word\"] or token[\"entity\"] == \"O\":\n            continue\n            \n        [b_or_i, entity_type] = token[\"entity\"].split(\"-\")\n        if entity_type not in raw_entities:\n            raw_entities[entity_type] = [token]\n            continue \n            \n        if b_or_i == \"B\":\n            raw_entities[entity_type].append(token)\n        elif b_or_i == \"I\":\n            raw_entities[entity_type][-1][\"end\"] = token[\"end\"]\n                \n    get_token = lambda token: sentence[token['start']:token['end']]\n        \n    entities = set()\n    for entity_type in raw_entities:\n        for entity in map(get_token, raw_entities[entity_type]):\n            entities.add(entity + \" (\" + entity_type +  \")\")\n        \n    return entities","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:11.459227Z","iopub.execute_input":"2023-09-27T09:03:11.459691Z","iopub.status.idle":"2023-09-27T09:03:17.013693Z","shell.execute_reply.started":"2023-09-27T09:03:11.459655Z","shell.execute_reply":"2023-09-27T09:03:17.012388Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422ffc8b23ae4e009feb484317bc2c7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911b6879a497400795497bd6c8042459"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b843f531e82742efaeb68e35bd7b8a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a213322a572c48da94f74c0d07adbd0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9381cb361f431d8311cf68f0a50d28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"498d5edbe68641ce849e012848c44dff"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using Sentence Transformers","metadata":{}},{"cell_type":"code","source":"# # load pre-trained similarity model\n\n# enc_options = dict(\n#     model = \"sentence-transformers/stsb-roberta-large\",\n#     dim = 1024,\n# )\nenc_options = dict(\n    model = \"sentence-transformers/all-MiniLM-L6-v2\",\n    dim = 384,\n)\n\nenc_model = SentenceTransformer(enc_options[\"model\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:19.959156Z","iopub.execute_input":"2023-09-27T09:03:19.960357Z","iopub.status.idle":"2023-09-27T09:03:22.792877Z","shell.execute_reply.started":"2023-09-27T09:03:19.960302Z","shell.execute_reply":"2023-09-27T09:03:22.791772Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7241791ea93b452f809c1c5ad6125d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147393930abb4793a095424bac7acc30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f111d38793864a75974c795a0f42460f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c21bb44f844491ac25fdc30874fef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d38c7d2f95c488fab4acf3482eac5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"526e034e224546bb99c02845193dd16e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64d4300443c418daf4e17cc5fb829ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b617d884c8c64cbe82b832250d694438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b582404e1bd4abe84c77b0715768edb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20dcb47f83047ed82bccc8c9c4c0efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084fa4e59f9045cd9d8839d045f9fe65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752c06635f5b48508f6e88d98d0c2424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6dafad32dc437988b058636fe58ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c6ddd5b400745a995d5c2868fcc451e"}},"metadata":{}}]},{"cell_type":"markdown","source":"Vector Database functionality","metadata":{}},{"cell_type":"code","source":"class VecDBQuery:\n    def __init__(self, data):\n        self.data = data\n    \n    def result(self):\n        return self.data\n    \n    def generate(\n        self, \n        mapper: str = None,\n        reducer: str = None,\n    ):\n        if not len(self.data):\n            return self\n        \n        mapper_args = get_keys(mapper)\n        reducer_args = get_keys(reducer)\n        \n        for i in range(len(self.data)):\n            self.data[i].update({\"_additional\": {\"generate\": {\n                \"singleResult\": None,\n                \"groupedResult\": None, \n            }}})\n        \n        if mapper and len(mapper_args):\n            for i, item in enumerate(self.data):\n                single_prompt = f\"{mapper}\\n\\n\" \n                for arg in mapper_args:\n                    single_prompt += f\"{arg}: {item[arg]}\\n\"\n                single_prompt_res = openai_generate(f\"{single_prompt}\\n\")\n                self.data[i][\"_additional\"][\"generate\"][\"singleResult\"] = single_prompt_res\n        \n        if reducer and len(reducer_args):\n            grouped_prompt = f\"{reducer}\\n\\n\"\n            for i, item in enumerate(self.data):\n                for arg in reducer_args:\n                    grouped_prompt += f\"{arg}[{i}]: {item[arg]}\\n\"\n            grouped_prompt_res = openai_generate(f\"{grouped_prompt}\\n\")\n            self.data[0][\"_additional\"][\"generate\"][\"groupedResult\"] = grouped_prompt_res\n\n        return self\n\nclass VecDB:\n    def __init__(\n        self, \n        conn: sqlite3.Cursor,\n        class_name: str,\n        keys: list[str],\n        vectorizer: dict[str, any],\n        maxchar: int = 1024,\n    ):\n        self.conn = conn\n        self.class_name = class_name\n        self.keys = list(sorted(keys))\n        self.indexed_keys = [\"row_num\", *self.keys]\n        self.maxchar = maxchar\n        \n        # create a table with given attributes\n        # all of which are string with specified max. length\n        columns = [f'{k} nvarchar({maxchar})' for k in self.keys]\n        self.conn.execute(f\"CREATE TABLE {class_name} ({' ,'.join(['row_num integer', *columns])})\")\n\n        # assign vector options\n        assert vectorizer is not None, \"vectorizer must be specified\"\n        \n        self.vectorizer_fn = vectorizer[\"encoder\"]\n        self.vectorized_key = vectorizer[\"key\"]\n        self.vectorizer_dim = vectorizer[\"dim\"]\n        \n        # create a vector database\n        vec_cols = [f'vec{i} float' for i in range(self.vectorizer_dim)]\n        self.conn.execute(f\"CREATE TABLE vectors ({' ,'.join(vec_cols)})\")\n    \n    def insert_data(\n        self,\n        data: list[dict[str, any]],\n    ):     \n        \n        # add placeholders for adding values\n        # then add each row of data\n        insert_query = f\"INSERT INTO {self.class_name} ({', '.join(self.indexed_keys)}) VALUES ({', '.join(['?']*len(self.indexed_keys))})\"\n        curr_i = self.conn.execute(f\"SELECT COUNT(row_num) FROM {self.class_name}\").fetchone()\n        for i, d in enumerate(data):\n            row_index = curr_i[0] + i\n            row_values = [row_index] + [d.get(k, '') for k in self.keys]\n            self.conn.execute(insert_query, row_values)\n        \n        # vectorize each data point and add to vector database\n        new_vectors = self.vectorizer_fn([d[self.vectorized_key] for d in data])\n        new_vector_tuples = [f\"({', '.join([str(n) for n in vector])})\" for vector in new_vectors]\n        self.conn.execute(f\"INSERT INTO vectors VALUES {', '.join(new_vector_tuples)}\")\n        \n        return self\n    \n    # WHERE\n    # path: if data looks like {\"a\": {\"b\": {\"c\": ...}}}, path is set to [\"a\", \"b\", \"c\"]\n    # operator: And Or Equal NotEqual GreaterThan GreaterThanEqual LessThan LessThanEqual Like WithinGeoRange IsNull ContainsAny ContainsAll\n    # valueText, valueInt, valueBoolean etc.\n    def query_data(\n        self,\n        keys: list[str] = None, \n        near_text: list[str] = None, \n        where: list[any] = None, \n        limit: int = None,\n    ):      \n        # get all vectors\n        vectors = np.array(self.conn.execute(\"SELECT * FROM vectors\").fetchall())\n        \n        select_query = f\"SELECT {', '.join(['row_num', *sorted(keys)])} FROM {self.class_name}\"\n        \n        # get where clauses\n        where_queries = []\n        for where_clause in where:\n            path = where_clause[\"path\"][0]\n            operator = where_clause[\"operator\"]\n            value_text = where_clause[\"valueText\"]\n            if operator == \"ContainsAny\":\n                patterns = [f\"{path} LIKE '%{val}%'\" for val in value_text]\n                where_queries.append('WHERE ' + ' OR '.join(patterns))\n        \n        # add where clauses and perform select\n        select_query = \" \".join([select_query, *where_queries])\n        vals = self.conn.execute(select_query).fetchall()\n\n        if not len(vals):\n            return VecDBQuery(vals)\n        \n        # vector update\n        vectors = vectors[[val[0] for val in vals]]\n        \n        min_len = min(limit, len(vals))\n        \n        # nearest neighbor search if near_text is specified\n        if near_text is not None:\n            near_vector = self.vectorizer_fn(\", \".join(near_text))\n            searchtree = spatial.KDTree(vectors)\n                \n            _, vec_ind = searchtree.query(near_vector, k=min_len)\n            \n            # vector update\n            vectors = vectors[vec_ind]\n            vals = [vals[i] for i in vec_ind]\n            \n            if not len(vals):\n                return VecDBQuery(vals)\n        \n        else:\n            vals = [vals[i] for i in range(min_len)]\n            vectors = vectors[:min_len]\n        \n        vals = [{k: v for k, v in zip(self.keys, val[1:])} for val in vals]\n        return VecDBQuery(vals)\n    \n    def drop(self):\n        # drop both tables\n        self.conn.execute(\"DROP TABLE vectors\")\n        self.conn.execute(f\"DROP TABLE {self.class_name}\")\n        return self","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:25.536811Z","iopub.execute_input":"2023-09-27T09:03:25.537194Z","iopub.status.idle":"2023-09-27T09:03:25.570354Z","shell.execute_reply.started":"2023-09-27T09:03:25.537163Z","shell.execute_reply":"2023-09-27T09:03:25.568907Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Local SQL connection","metadata":{}},{"cell_type":"code","source":"connection = sqlite3.connect(\"sqlite://\")\nconn = connection.cursor()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:34.287630Z","iopub.execute_input":"2023-09-27T09:03:34.288011Z","iopub.status.idle":"2023-09-27T09:03:34.293549Z","shell.execute_reply.started":"2023-09-27T09:03:34.287983Z","shell.execute_reply":"2023-09-27T09:03:34.292430Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Collect and preprocess data","metadata":{}},{"cell_type":"code","source":"class_name = \"statements\"\n\ntts = pd.read_csv(\"../input/trump-tweets/trumptweets.csv\",usecols=[\"content\"])\nsentences = list(tts[\"content\"].values)[:100]\n\ndata = [\n    dict(\n        statement=s, \n        entities=', '.join(topics(s)),\n    ) for s in sentences\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:36.515934Z","iopub.execute_input":"2023-09-27T09:03:36.516945Z","iopub.status.idle":"2023-09-27T09:03:46.927660Z","shell.execute_reply.started":"2023-09-27T09:03:36.516903Z","shell.execute_reply":"2023-09-27T09:03:46.926175Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Initialize a vector database and insert data into it","metadata":{}},{"cell_type":"code","source":"client = VecDB(\n    conn,\n    class_name, \n    keys = [\"statement\", \"entities\"],\n    vectorizer = dict(\n        encoder = enc_model.encode,\n        key = \"statement\",\n        dim = enc_options[\"dim\"],\n    ),\n)\n\nclient.insert_data(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:49.168030Z","iopub.execute_input":"2023-09-27T09:03:49.168585Z","iopub.status.idle":"2023-09-27T09:03:50.677989Z","shell.execute_reply.started":"2023-09-27T09:03:49.168539Z","shell.execute_reply":"2023-09-27T09:03:50.676587Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48feecb28df1473b9fd3f88cbe44c91b"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7f8c9ada9900>"},"metadata":{}}]},{"cell_type":"markdown","source":"Insert more data into the vector database","metadata":{}},{"cell_type":"code","source":"client.insert_data([\n    {\n        \"statement\": \"Donald Trump didn't build any wall in Mexican borders. He built margins.\",\n        \"entities\": \"Donald Trump (PER)\"\n    },\n    {\n        \"statement\": \"Donald Trump seems to be an inspiring character, but I can assure it's the opposite. He doesn't want you to know that he is betraying the US politics. #AmericanDream\",\n        \"entities\": \"Donald Trump (PER)\"\n    }\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:53.938267Z","iopub.execute_input":"2023-09-27T09:03:53.938679Z","iopub.status.idle":"2023-09-27T09:03:54.013120Z","shell.execute_reply.started":"2023-09-27T09:03:53.938649Z","shell.execute_reply":"2023-09-27T09:03:54.011957Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9095aa1f81424d4181ffa840040cd4e3"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7f8c9ada9900>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, feel free to query data by using `query_data` and generate additional output using OpenAI","metadata":{}},{"cell_type":"code","source":"client\\\n    .query_data(\n        keys = [\"statement\", \"entities\"],\n        near_text = [\"wall\", \"politics\"],\n        where = [dict(\n            path = [\"entities\"],\n            operator = \"ContainsAny\",\n            valueText = [\"Donald J. Trump\", \"Donald Trump\"],\n        )],\n        limit = 10,\n    )\\\n    .generate(\n        mapper = \"Extract the facts out of {statement}, also take away the human factor. Results have to be returned in a list of sentences.\",\n        reducer = \"You are a natural language inference engine. Given many {statement}s, find the conflicting statements (i, j) and return those pairs in a Python list (otherwise return []).\",\n    )\\\n    .result()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:56.387614Z","iopub.execute_input":"2023-09-27T09:03:56.388001Z","iopub.status.idle":"2023-09-27T09:04:04.777910Z","shell.execute_reply.started":"2023-09-27T09:03:56.387971Z","shell.execute_reply":"2023-09-27T09:04:04.776545Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8dc7fc74de74c1e8bc083b9a14a4fd8"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[{'entities': 'Donald J. Trump (PER)',\n  'statement': '\"My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Building walls is preferable to clinging to them.\\n2. It is not desirable to be a wallflower.',\n    'groupedResult': '\\nAnswer: []'}}},\n {'entities': 'Donald Trump (PER)',\n  'statement': \"Donald Trump didn't build any wall in Mexican borders. He built margins.\",\n  '_additional': {'generate': {'singleResult': '\\n1. A wall was not built in Mexican borders.\\n2. Margins were built.',\n    'groupedResult': None}}},\n {'entities': 'David Letter (PER), Donald Trump (PER), The Late Show (MISC)',\n  'statement': \"-- Watch Donald Trump's recent appearance on The Late Show with David Letterman: http://tinyurl.com/klts6b\",\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Donald Trump appeared on The Late Show with David Letterman.\\n2. A link to the appearance is http://tinyurl.com/klts6b.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), ‘Connect the World’ as ‘Connector of the Day (MISC), CNN International (ORG)',\n  'statement': 'Donald Trump appearing today on CNN International’s ‘Connect the World’ as ‘Connector of the Day’. Submit questions: http://bit.ly/bPiP7T',\n  '_additional': {'generate': {'singleResult': \"\\n\\n1. Donald Trump appeared on CNN International's 'Connect the World' today.\\n2. A link to submit questions was provided: http://bit.ly/bPiP7T.\",\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"You have to know when to call it quits and when to keep moving forward.\" --Donald J. Trump http://www.trumpthinklikeachampion.com',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. It is beneficial to know when to end something.\\n2. It is beneficial to know when to continue something.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Facebook (LOC), Donald (MISC)',\n  'statement': 'Did you know Donald Trump is on Facebook? http://www.facebook.com/DonaldTrump - Become a fan today!',\n  '_additional': {'generate': {'singleResult': \"\\n\\n1. Donald Trump has a Facebook page.\\n2. The URL for Donald Trump's Facebook page is http://www.facebook.com/DonaldTrump.\",\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"We win in our lives by having a champion\\'s view of each moment.\" --Donald J. Trump http://tinyurl.com/pqpfvm',\n  '_additional': {'generate': {'singleResult': \"\\n1. Winning in life is possible.\\n2. Having a champion's view of each moment is beneficial.\",\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Think Like A Champion (MISC)',\n  'statement': 'Listen to an interview with Donald Trump discussing his new book, Think Like A Champion: http://tinyurl.com/qs24vl',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Donald Trump has written a book titled Think Like A Champion.\\n2. The book is available for listening in an interview format.\\n3. The interview can be accessed via the URL http://tinyurl.com/qs24vl.',\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"Keep it fast, short and direct - whatever it is.\" --Donald J. Trump http://tinyurl.com/pqpfvm',\n  '_additional': {'generate': {'singleResult': '\\n1. Keep it fast.\\n2. Keep it short.\\n3. Keep it direct.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Neil C (PER), Your World (MISC)',\n  'statement': 'Hear Donald Trump discuss big gov spending, banks, & taxes on Your World w/Neil Cavuto: http://tinyurl.com/yhnzd7p',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Government spending is discussed.\\n2. Banks are discussed.\\n3. Taxes are discussed.',\n    'groupedResult': None}}}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Drop the both tables","metadata":{}},{"cell_type":"code","source":"client.drop()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:04:15.064467Z","iopub.execute_input":"2023-09-27T09:04:15.064853Z","iopub.status.idle":"2023-09-27T09:04:15.074065Z","shell.execute_reply.started":"2023-09-27T09:04:15.064824Z","shell.execute_reply":"2023-09-27T09:04:15.073071Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7f8c9ada9900>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}