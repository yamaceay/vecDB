{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning\n\nLLM: \n- https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32\n\nSent-Transformer:\n- https://huggingface.co/blog/how-to-train-sentence-transformers\n- https://huggingface.co/datasets/snli\n","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!pip install openai transformers sentence-transformers\n\nfrom kaggle_secrets import UserSecretsClient\n\nimport openai\nimport re\nimport json\nimport sqlite3\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import spatial\n\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\nfrom sentence_transformers import SentenceTransformer\n\n# load pre-trained similarity model\n# encoder_options = {\"pretrained\": 'sentence-transformers/stsb-roberta-large',\"dim\": 1024}\nencoder_options = {\"pretrained\": \"sentence-transformers/all-MiniLM-L6-v2\",\"dim\": 384}\nmodel = SentenceTransformer(encoder_options[\"pretrained\"])\n\nopenai.api_key = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")\n   \ndef openai_generate(prompt: str, model: str = \"text-davinci-003\"):\n    res = openai.Completion.create(\n        model=model,\n        prompt=prompt,\n        temperature=0,\n        max_tokens=1024,\n    )\n    \n    choice = res.choices[0]\n    if choice.finish_reason != \"stop\":\n        raise Exception(f\"finish reason: {choice.finish_reason}\")\n    return choice.text\n\nner_tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\nner_model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\nner = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n\n# get important topics / tags of a sentence\ndef topics(sentence, ner = ner):\n    raw_entities = {}\n    for token in ner(sentence):\n        if '#' in token[\"word\"] or token[\"entity\"] == \"O\":\n            continue\n            \n        [b_or_i, entity_type] = token[\"entity\"].split(\"-\")\n        if entity_type not in raw_entities:\n            raw_entities[entity_type] = [token]\n            continue \n            \n        if b_or_i == \"B\":\n            raw_entities[entity_type].append(token)\n        elif b_or_i == \"I\":\n            raw_entities[entity_type][-1][\"end\"] = token[\"end\"]\n                \n    get_token = lambda token: sentence[token['start']:token['end']]\n        \n    entities = set()\n    for entity_type in raw_entities:\n        for entity in map(get_token, raw_entities[entity_type]):\n            entities.add(entity + \" (\" + entity_type +  \")\")\n        \n    return entities\n    \ndef get_keys(s: str): \n    res = re.findall(r\"\\{\\S+?\\}\", s)\n    res = [re.sub(r\"[\\{\\}]\", '', item) for item in res]\n    return res\n    \nclass VecDBQuery:\n    def __init__(self, data):\n        self.data = data\n    \n    def result(self):\n        return self.data\n    \n    def generate(\n        self, \n        mapper: str = None,\n        reducer: str = None,\n    ):\n        if not len(self.data):\n            return self\n        \n        mapper_args = get_keys(mapper)\n        reducer_args = get_keys(reducer)\n        \n        for i in range(len(self.data)):\n            self.data[i].update({\"_additional\": {\"generate\": {\n                \"singleResult\": None,\n                \"groupedResult\": None, \n            }}})\n        \n        if mapper and len(mapper_args):\n            for i, item in enumerate(self.data):\n                single_prompt = f\"{mapper}\\n\\n\" \n                for arg in mapper_args:\n                    single_prompt += f\"{arg}: {item[arg]}\\n\"\n                single_prompt_res = openai_generate(f\"{single_prompt}\\n\")\n                self.data[i][\"_additional\"][\"generate\"][\"singleResult\"] = single_prompt_res\n        \n        if reducer and len(reducer_args):\n            grouped_prompt = f\"{reducer}\\n\\n\"\n            for i, item in enumerate(self.data):\n                for arg in reducer_args:\n                    grouped_prompt += f\"{arg}[{i}]: {item[arg]}\\n\"\n            grouped_prompt_res = openai_generate(f\"{grouped_prompt}\\n\")\n            self.data[0][\"_additional\"][\"generate\"][\"groupedResult\"] = grouped_prompt_res\n\n        return self\n\nclass VecDB:\n    def __init__(\n        self, \n        conn: sqlite3.Cursor,\n        class_name: str,\n        keys: list[str] = [],\n        vectorizer: dict[str, any] = None,\n        maxchar: int = 1024,\n    ):\n        self.conn = conn\n        self.class_name = class_name\n        self.keys = list(sorted(keys))\n        self.maxchar = maxchar\n        \n        columns = [f'{k} nvarchar({maxchar})' for k in self.keys]\n        self.conn.execute(f\"CREATE TABLE {class_name} ({' ,'.join(['row_num integer', *columns])})\")\n\n        if vectorizer is not None:\n            self.vectorizer_fn = vectorizer[\"encoder\"]\n            self.vectorized_key = vectorizer[\"key\"]\n            self.vectorizer_dim = vectorizer[\"dim\"]\n            vec_cols = [f'vec{i} float' for i in range(self.vectorizer_dim)]\n            self.conn.execute(f\"CREATE TABLE vectors ({' ,'.join(vec_cols)})\")\n    \n    def insert_data(\n        self,\n        data: list[dict[str, any]],\n    ):     \n        new_vectors = self.vectorizer_fn([d[self.vectorized_key] for d in data])\n        new_vector_tuples = [f\"({', '.join([str(n) for n in vector])})\" for vector in new_vectors]\n        indexed_keys = [\"row_num\", *self.keys]\n        val_cmd = f\"INSERT INTO {self.class_name} ({', '.join(indexed_keys)}) VALUES ({', '.join(['?']*len(indexed_keys))})\"\n        curr_i = conn.execute(f\"SELECT COUNT(row_num) FROM {class_name}\").fetchone()\n        for i, d in enumerate(data):\n            conn.execute(val_cmd, [curr_i[0] + i] + [d.get(k, '') for k in self.keys])\n        conn.execute(f\"INSERT INTO vectors VALUES {', '.join(new_vector_tuples)}\")\n        return self\n    \n    # WHERE\n    # path: if data looks like {\"a\": {\"b\": {\"c\": ...}}}, path is set to [\"a\", \"b\", \"c\"]\n    # operator: And Or Equal NotEqual GreaterThan GreaterThanEqual LessThan LessThanEqual Like WithinGeoRange IsNull ContainsAny ContainsAll\n    # valueText, valueInt, valueBoolean etc.\n    def query_data(\n        self,\n        keys: list[str] = None, \n        near_text: list[str] = None, \n        where: list[any] = None, \n        limit: int = None,\n    ):      \n        # vertical update\n        vectors = np.array(conn.execute(\"SELECT * FROM vectors\").fetchall())\n        indexed_keys = [\"row_num\", *sorted(keys)]\n        val_query = f\"SELECT {', '.join(indexed_keys)} FROM {self.class_name}\"\n        \n        where_queries = []\n        for where_clause in where:\n            path = where_clause[\"path\"][0]\n            operator = where_clause[\"operator\"]\n            value_text = where_clause[\"valueText\"]\n            if operator == \"ContainsAny\":\n                patterns = [f\"{path} LIKE '%{val}%'\" for val in value_text]\n                where_queries.append('WHERE ' + ' OR '.join(patterns))\n        \n        val_query = \" \".join([val_query, *where_queries])\n        vals = conn.execute(val_query).fetchall()\n        if not len(vals):\n            return VecDBQuery(vals)\n        \n        vectors = vectors[[val[0] for val in vals]]\n        min_len = min(limit, len(vals))\n        \n        if near_text is not None:\n            near_vector = self.vectorizer_fn(\", \".join(near_text))\n            searchtree = spatial.KDTree(vectors)\n                \n            _, vec_ind = searchtree.query(near_vector, k=min_len)\n            \n            # vertical update\n            vectors = vectors[vec_ind]\n            vals = [vals[i] for i in vec_ind]\n            if not len(vals):\n                return VecDBQuery(vals)\n        \n        else:\n            vals = [vals[i] for i in range(min_len)]\n            vectors = vectors[:min_len]\n        \n        vals = [{k: v for k, v in zip(self.keys, val[1:])} for val in vals]\n        return VecDBQuery(vals)\n    \n    def drop(self):\n        self.conn.execute(\"DROP TABLE vectors\")\n        self.conn.execute(\"DROP TABLE statements\")\n        return self","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"connection = sqlite3.connect(\"sqlite://\")\nconn = connection.cursor()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:49:24.536588Z","iopub.execute_input":"2023-09-27T07:49:24.537026Z","iopub.status.idle":"2023-09-27T07:49:24.544551Z","shell.execute_reply.started":"2023-09-27T07:49:24.536989Z","shell.execute_reply":"2023-09-27T07:49:24.543521Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tts = pd.read_csv(\"../input/trump-tweets/trumptweets.csv\",usecols=[\"content\"])\nsentences = list(tts[\"content\"].values)[:100]","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:50:28.039536Z","iopub.execute_input":"2023-09-27T07:50:28.039976Z","iopub.status.idle":"2023-09-27T07:50:28.416102Z","shell.execute_reply.started":"2023-09-27T07:50:28.039940Z","shell.execute_reply":"2023-09-27T07:50:28.414893Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class_name = \"statements\"\ndata = [\n    dict(\n        statement=s, \n        entities=', '.join(topics(s)),\n    ) for s in sentences\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:50:30.030621Z","iopub.execute_input":"2023-09-27T07:50:30.031432Z","iopub.status.idle":"2023-09-27T07:50:39.809729Z","shell.execute_reply.started":"2023-09-27T07:50:30.031389Z","shell.execute_reply":"2023-09-27T07:50:39.808521Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"client = VecDB(\n    conn,\n    class_name, \n    keys = [\"statement\", \"entities\"],\n    vectorizer = dict(\n        encoder = model.encode,\n        key = \"statement\",\n        dim = encoder_options[\"dim\"],\n    ),\n)\n\nclient.insert_data(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:51:07.319922Z","iopub.execute_input":"2023-09-27T07:51:07.320342Z","iopub.status.idle":"2023-09-27T07:51:08.662868Z","shell.execute_reply.started":"2023-09-27T07:51:07.320307Z","shell.execute_reply":"2023-09-27T07:51:08.661635Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc86e87d57647e6813ddc70633752d4"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7cc97615fb20>"},"metadata":{}}]},{"cell_type":"code","source":"client.insert_data([\n    {\n        \"statement\": \"Donald Trump didn't build any wall in Mexican borders. He built margins.\",\n        \"entities\": \"Donald Trump (PER)\"\n    },\n    {\n        \"statement\": \"Donald Trump seems to be an inspiring character, but I can assure it's the opposite. He doesn't want you to know that he is betraying the US politics. #AmericanDream\",\n        \"entities\": \"Donald Trump (PER)\"\n    }\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:51:30.899479Z","iopub.execute_input":"2023-09-27T07:51:30.899917Z","iopub.status.idle":"2023-09-27T07:51:30.970939Z","shell.execute_reply.started":"2023-09-27T07:51:30.899885Z","shell.execute_reply":"2023-09-27T07:51:30.969859Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42d2c42acfe4dbf867de86c252c2300"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7cc97615fb20>"},"metadata":{}}]},{"cell_type":"code","source":"client\\\n    .query_data(\n        keys = [\"statement\", \"entities\"],\n        near_text = [\"wall\", \"politics\"],\n        where = [dict(\n            path = [\"entities\"],\n            operator = \"ContainsAny\",\n            valueText = [\"Donald J. Trump\", \"Donald Trump\"],\n        )],\n        limit = 10,\n    )\\\n    .generate(\n        mapper = \"Extract the facts out of {statement}, also take away the human factor. Results have to be returned in a list of sentences.\",\n        reducer = \"You are a natural language inference engine. Given many {statement}s, find the conflicting statements (i, j) and return those pairs in a Python list (otherwise return []).\",\n    )\\\n    .result()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:52:57.366989Z","iopub.execute_input":"2023-09-27T07:52:57.367378Z","iopub.status.idle":"2023-09-27T07:53:06.629933Z","shell.execute_reply.started":"2023-09-27T07:52:57.367348Z","shell.execute_reply":"2023-09-27T07:53:06.628759Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ece6b8b31c4e54a56915f08c5b7593"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'entities': 'Donald J. Trump (PER)',\n  'statement': '\"My persona will never be that of a wallflower - I’d rather build walls than cling to them\" --Donald J. Trump',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Building walls is preferable to clinging to them.\\n2. It is not desirable to be a wallflower.',\n    'groupedResult': '\\nAnswer: []'}}},\n {'entities': 'Donald Trump (PER)',\n  'statement': \"Donald Trump didn't build any wall in Mexican borders. He built margins.\",\n  '_additional': {'generate': {'singleResult': '\\n1. A wall was not built in Mexican borders.\\n2. Margins were built.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), The Late Show (MISC), David Letter (PER)',\n  'statement': \"-- Watch Donald Trump's recent appearance on The Late Show with David Letterman: http://tinyurl.com/klts6b\",\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Donald Trump appeared on The Late Show with David Letterman.\\n2. A link to the appearance is http://tinyurl.com/klts6b.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), CNN International (ORG), ‘Connect the World’ as ‘Connector of the Day (MISC)',\n  'statement': 'Donald Trump appearing today on CNN International’s ‘Connect the World’ as ‘Connector of the Day’. Submit questions: http://bit.ly/bPiP7T',\n  '_additional': {'generate': {'singleResult': \"\\n\\n1. Donald Trump appeared on CNN International's 'Connect the World' today.\\n2. A link to submit questions was provided: http://bit.ly/bPiP7T.\",\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"You have to know when to call it quits and when to keep moving forward.\" --Donald J. Trump http://www.trumpthinklikeachampion.com',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. It is beneficial to know when to end something.\\n2. It is beneficial to know when to continue something.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Facebook (LOC), Donald (MISC)',\n  'statement': 'Did you know Donald Trump is on Facebook? http://www.facebook.com/DonaldTrump - Become a fan today!',\n  '_additional': {'generate': {'singleResult': \"\\n\\n1. Donald Trump has a Facebook page.\\n2. The URL for Donald Trump's Facebook page is http://www.facebook.com/DonaldTrump.\",\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"We win in our lives by having a champion\\'s view of each moment.\" --Donald J. Trump http://tinyurl.com/pqpfvm',\n  '_additional': {'generate': {'singleResult': \"\\n1. Winning in life is possible.\\n2. Having a champion's view of each moment is beneficial.\",\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Think Like A Champion (MISC)',\n  'statement': 'Listen to an interview with Donald Trump discussing his new book, Think Like A Champion: http://tinyurl.com/qs24vl',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Donald Trump has written a book titled Think Like A Champion.\\n2. The book is available for listening in an interview format.\\n3. The interview can be accessed via the URL http://tinyurl.com/qs24vl.',\n    'groupedResult': None}}},\n {'entities': 'Donald J. Trump (PER)',\n  'statement': '\"Keep it fast, short and direct - whatever it is.\" --Donald J. Trump http://tinyurl.com/pqpfvm',\n  '_additional': {'generate': {'singleResult': '\\n1. Keep it fast.\\n2. Keep it short.\\n3. Keep it direct.',\n    'groupedResult': None}}},\n {'entities': 'Donald Trump (PER), Neil C (PER), Your World (MISC)',\n  'statement': 'Hear Donald Trump discuss big gov spending, banks, & taxes on Your World w/Neil Cavuto: http://tinyurl.com/yhnzd7p',\n  '_additional': {'generate': {'singleResult': '\\n\\n1. Government spending is discussed.\\n2. Banks are discussed.\\n3. Taxes are discussed.',\n    'groupedResult': None}}}]"},"metadata":{}}]},{"cell_type":"code","source":"client.drop()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T07:53:06.709534Z","iopub.execute_input":"2023-09-27T07:53:06.709949Z","iopub.status.idle":"2023-09-27T07:53:06.720012Z","shell.execute_reply.started":"2023-09-27T07:53:06.709908Z","shell.execute_reply":"2023-09-27T07:53:06.718936Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<__main__.VecDB at 0x7cc97615fb20>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}